{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required module\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings;warnings.filterwarnings('ignore');\n",
    "\n",
    "import spacy\n",
    "# python -m spacy download en_core_web_sm\n",
    "# Load the en_core_web_sm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "label    5572 non-null object\n",
      "text     5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Couldn't Go until jurong point, crazy.. Availa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Couldn't Go until jurong point, crazy.. Availa...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading Data\n",
    "# Determining weather message is spam or not\n",
    "data = pd.read_csv(\"D:\\Ravi_Data\\spam.csv\", encoding = 'latin-1')\n",
    "data = data[['label','text']]\n",
    "print(data.info())\n",
    "\n",
    "data['label'] = data['label'].apply(lambda x: 1 if x == \"spam\" else 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[could, jurong, point, crazy, available, bugis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[u, dun, early, hor, u, c]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[nah, think, usf, live]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  [could, jurong, point, crazy, available, bugis...\n",
       "1      0                     [ok, lar, joking, wif, u, oni]\n",
       "2      1  [free, entry, wkly, comp, win, fa, cup, final,...\n",
       "3      0                         [u, dun, early, hor, u, c]\n",
       "4      0                            [nah, think, usf, live]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inansiating Spacy and tokonizing text variable\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# stop word list in spacy for english words\n",
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "def processing(text):\n",
    "    \n",
    "  \t# Create Doc object\n",
    "    global doc \n",
    "    doc = nlp(text, disable=['ner', 'parser'])\n",
    "    # Generate lemmas\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    # Only if word doesn't start with capital letter. remove stopwords and non-alphabetic characters\n",
    "    clean = []\n",
    "    for lemma in lemmas:\n",
    "        if lemma[0].isupper():\n",
    "            clean.append(lemma)\n",
    "        else:\n",
    "            if lemma.isalpha() and lemma not in stopwords:\n",
    "                clean.append(lemma)\n",
    "    cleaned = [x.lower() for x in clean]\n",
    "    return cleaned\n",
    "\n",
    "data['text'] = data['text'].apply(processing)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0  could point crazy available bugis n great worl...\n",
      "1                                   ok lar wif u oni\n",
      "2  free entry wkly comp win fa cup final tkts may...\n",
      "3                                u dun early hor u c\n",
      "4                                 nah think usf live\n"
     ]
    }
   ],
   "source": [
    "# Removing words which appeared only once in all document combined\n",
    "from collections import defaultdict\n",
    "\n",
    "frequency = defaultdict(int)\n",
    "for text in data['text']:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "data['text'] = [[token for token in text if frequency[token] > 1]for text in data['text']]\n",
    "\n",
    "# joining all token again in sentences\n",
    "data['text'] = data['text'].apply(lambda x : ' '.join(x))\n",
    "print(data[['text']].head())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating additional features from POS & NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pnoun</th>\n",
       "      <th>noun</th>\n",
       "      <th>num</th>\n",
       "      <th>adj</th>\n",
       "      <th>nnp</th>\n",
       "      <th>pers</th>\n",
       "      <th>money</th>\n",
       "      <th>org</th>\n",
       "      <th>gpe</th>\n",
       "      <th>ordi</th>\n",
       "      <th>war</th>\n",
       "      <th>event</th>\n",
       "      <th>fac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pnoun  noun  num  adj  nnp  pers  money  org  gpe  ordi  war  event  fac\n",
       "0    6.0   1.0  0.0  3.0  6.0   0.0    0.0  0.0  0.0   0.0  0.0    0.0  0.0\n",
       "1    4.0   0.0  0.0  0.0  4.0   0.0    0.0  0.0  0.0   0.0  0.0    0.0  0.0\n",
       "2    4.0   3.0  0.0  2.0  4.0   0.0    0.0  0.0  0.0   0.0  0.0    0.0  0.0\n",
       "3    6.0   0.0  0.0  0.0  6.0   0.0    0.0  0.0  0.0   0.0  0.0    0.0  0.0\n",
       "4    0.0   1.0  0.0  0.0  0.0   0.0    0.0  0.0  0.0   0.0  0.0    0.0  0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pos= [\"PROPN\",\"NOUN\",\"NUM\",\"ADJ\"]\n",
    "#tag =['NNP','PERSON','MONEY','ORG','GPE','ORDINAL','WORK_OF_ART','EVENT','FAC']\n",
    "    \n",
    "file = data['text'].tolist()\n",
    "\n",
    "\n",
    "def pos_tag_features(list):\n",
    "    \n",
    "    n = len(list)\n",
    "    pnoun,noun,num,adj,nnp,pers,money,org,gpe,ordi,war,event,fac = (np.zeros(n) for k in range(13))\n",
    "\n",
    "    for i,text in enumerate(list):\n",
    "        doc = nlp(text,disable=['ner', 'parser'])\n",
    "        pos = [token.pos_ for token in doc]\n",
    "        pnoun[i] = pos.count(\"PROPN\")\n",
    "        noun[i] = pos.count(\"NOUN\")\n",
    "        num[i] = pos.count(\"NUM\")\n",
    "        adj[i] = pos.count(\"ADJ\")\n",
    "        \n",
    "        tag = [token.tag_ for token in doc]\n",
    "        nnp[i] = tag.count(\"NNP\")\n",
    "        pers[i] = tag.count(\"PERSON\")\n",
    "        money[i] = tag.count(\"MONEY\")\n",
    "        org[i] = tag.count(\"ORG\")\n",
    "        gpe[i] = tag.count(\"GPE\")\n",
    "        ordi[i]= tag.count(\"ORDINAL\")\n",
    "        war[i] = tag.count(\"WORK_OF_ART\")\n",
    "        event[i] = tag.count(\"EVENT\")\n",
    "        fac[i] = tag.count(\"FAC\") \n",
    "        \n",
    "    return pd.DataFrame({\"pnoun\":pnoun,\"noun\":noun,\"num\":num,\"adj\":adj,\"nnp\":nnp,\"pers\":pers,\n",
    "                         \"money\":money,\"org\":org,\"gpe\":gpe,\"ordi\":ordi,\"war\":war,\"event\":event,\"fac\":fac})\n",
    "    \n",
    "        \n",
    "pos_tag_DF = pos_tag_features(file)\n",
    "pos_tag_DF.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection from newly created features ( Fisher score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works for binary classification\n",
    "# work better if independent features are numeric.\n",
    "# Standardization is not needed\n",
    "# It finds importance of each feature independently based on its binary claasification variance\n",
    "# Input of function must be DataFrame and Target varible name\n",
    "# Higher Fisher score higher importance\n",
    "\n",
    "def fisherScore(df, target):\n",
    "    fisher_score = []\n",
    "    y = np.unique(df[target])\n",
    "    df_col = df.columns.tolist()\n",
    "    df_col.remove(target)\n",
    "    for col in df_col:\n",
    "        abs_mean_diff = abs(df[df[target] == y[0]][col].mean() - df[df[target] == y[1]][col].mean())\n",
    "        sqrt_var = np.sqrt(df[df[target] == y[0]][col].var() + df[df[target] == y[1]][col].var())\n",
    "        fisher = abs_mean_diff / sqrt_var\n",
    "        fisher_score.append(fisher.round(3))\n",
    "        \n",
    "    scoreDF = pd.DataFrame({'Column Name':df_col,'Fisher Score':fisher_score}).sort_values('Fisher Score', ascending = False)\n",
    "    return scoreDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Fisher Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>noun</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pnoun</td>\n",
       "      <td>0.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nnp</td>\n",
       "      <td>0.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adj</td>\n",
       "      <td>0.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pers</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>money</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>org</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpe</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ordi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>war</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>event</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fac</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column Name  Fisher Score\n",
       "1         noun         0.698\n",
       "0        pnoun         0.650\n",
       "4          nnp         0.646\n",
       "3          adj         0.504\n",
       "2          num         0.039\n",
       "5         pers           NaN\n",
       "6        money           NaN\n",
       "7          org           NaN\n",
       "8          gpe           NaN\n",
       "9         ordi           NaN\n",
       "10         war           NaN\n",
       "11       event           NaN\n",
       "12         fac           NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining pos_tag_DF with label df \n",
    "df = pd.concat([pos_tag_DF,data[['label']]], axis=1)\n",
    "\n",
    "# Creating Fisher score\n",
    "result = fisherScore(df=df,target=\"label\")\n",
    "\n",
    "# only 4 newly created features are relevent so selecting only those and will be combined with base table.\n",
    "reduced = result[\"Column Name\"].head(4).tolist()\n",
    "pos_tag_DF_fisher = pos_tag_DF[reduced]\n",
    "\n",
    "# Higher Fisher score higher importance\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combning with base data dataframe and then do train test split\n",
    "\n",
    "# loading sciki learn libraries and spliting data into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['text'],data['label'],test_size=0.3,\n",
    "                                                    random_state = 111,stratify =data['label'],shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words creation and vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english',max_df=0.7)\n",
    "\n",
    "# Tfidf vectorizer fit and transform\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_train_array = tfidf_train.toarray() \n",
    "# only transform X test data set\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "tfidf_test_array = tfidf_test.toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 11., 11.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ...,  1.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  9.,  9.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting and Combining POS_Tag dataframe with vectorized data fame \n",
    "# indices of X train and test\n",
    "train_index =  X_train.index\n",
    "test_index = X_test.index\n",
    "\n",
    "pos_tag_train_array = pos_tag_DF_fisher.iloc[train_index,:].values\n",
    "pos_tag_test_array = pos_tag_DF_fisher.iloc[test_index,:].values\n",
    "\n",
    "\n",
    "final_train = np.concatenate((tfidf_train_array,pos_tag_train_array ), axis=1)\n",
    "final_test = np.concatenate((tfidf_test_array,pos_tag_test_array ), axis=1)\n",
    "final_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(final_train,y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.96\n",
      "Fbeta : 0.91\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Model\n",
    "score = metrics.accuracy_score(y_test,pred)\n",
    "print(\"Score :\",score.round(2))\n",
    "print(\"Fbeta :\",metrics.fbeta_score(y_test,pred, beta = 0.5).round(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
